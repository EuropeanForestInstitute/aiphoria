{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataProvider: Reading data from file 'data/example_data.xlsx'...\n",
      "Checking data integrity, detecting year range from file: True\n",
      "Checking stock distribution types...\n",
      "Checking stock distribution parameters...\n",
      "Checking process total inflows and total outflows mismatches...\n",
      "Total inflows and total outflows for process 'P3:EU' does not match.\n",
      "Absolute difference of total inflows and total outflows was 1.0\n",
      "Check following inflows in Excel sheet 'Flows':\n",
      "- flow 'P2:EU P3:EU' in row 5\n",
      "Check following outflows:\n",
      "- flow 'P3:EU P5:EU' in row 7\n",
      "\n",
      "Total inflows and total outflows for process 'P3:EU' does not match.\n",
      "Absolute difference of total inflows and total outflows was 1.0\n",
      "Check following inflows in Excel sheet 'Flows':\n",
      "- flow 'P2:EU P3:EU' in row 14\n",
      "Check following outflows:\n",
      "- flow 'P3:EU P5:EU' in row 16\n",
      "\n",
      "Using year range 2021 - 2022\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from core.dataprovider import DataProvider\n",
    "from core.datachecker import DataChecker\n",
    "from core.datavisualizer import DataVisualizer\n",
    "from core.flowsolver import FlowSolver\n",
    "\n",
    "# Path configuration\n",
    "MainPath = os.path.join('.')\n",
    "sys.path.insert(0, MainPath)\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '.', 'lib', 'odym', 'modules'))\n",
    "\n",
    "# ODYM classes\n",
    "import ODYM_Classes as msc\n",
    "import dynamic_stock_model as dsm\n",
    "\n",
    "# For Ipython Notebook only\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# **********************************************\n",
    "# * Step 1: Define parameters for the aiphoria *\n",
    "# **********************************************\n",
    "model_params = {\n",
    "    # Path (either relative or absolute) to the Excel file that contains the data for Processes and Flows\n",
    "    # Path to the Excel file that contains data for the Processes and Flows\n",
    "    # Path can be either:\n",
    "    #   relative path (e.g. \"/data/data.xlsx\") or\n",
    "    #   absolute path (e.g. \"C:\\aiphoria\\data\\data.xlsx\")\n",
    "    \"filename\": \"data/example_data.xlsx\",\n",
    "\n",
    "    # *************\n",
    "    # * Processes *\n",
    "    # *************\n",
    "    # Name of the sheet in Excel file that contains data for Processes\n",
    "    \"sheet_name_processes\": \"Processes\",\n",
    "\n",
    "    # Column range that contains data for the Processes\n",
    "    # The both starting and ending columns are included in the range\n",
    "    # (e.g. \"A:B\" means columns A, B, and C)\n",
    "    \"column_range_processes\": \"B:R\",\n",
    "\n",
    "    # Number of rows to skip when reading sheet for Process data\n",
    "    # Header line must be the first line read (in this case row 3 would contain the header)\n",
    "    \"skip_num_rows_processes\": 2,\n",
    "\n",
    "\n",
    "    # *********\n",
    "    # * Flows *\n",
    "    # *********\n",
    "    # Name of the sheet in Excel file that contains data for Flows\n",
    "    \"sheet_name_flows\": \"Flows\",\n",
    "\n",
    "    # Column range that contains data for the Flows\n",
    "    # Only the starting column is included in the range, not the ending column!\n",
    "    # (e.g. \"A:C\" means columns A and B)\n",
    "    \"column_range_flows\": \"B:U\",\n",
    "\n",
    "    # Number of rows to skip when reading sheet for Flow data\n",
    "    # Header line must be the first line read (in this case row 3 would contain the header)\n",
    "    \"skip_num_rows_flows\": 2,\n",
    "\n",
    "\n",
    "    # ********************\n",
    "    # * Model parameters *\n",
    "    # ********************\n",
    "    # Starting year of the model, this needs to be found from the Excel file\n",
    "    \"year_start\": 2021,\n",
    "\n",
    "    # Ending year of the model, this can be extended as far as needed\n",
    "    # The last existing year data is copied to the non-existing years\n",
    "    # Last year is included in the time range\n",
    "    \"year_end\": 2031,\n",
    "\n",
    "    # Should the model detect year range automatically from file?\n",
    "    # True overrides year_start and year_end values\n",
    "    \"detect_year_range\": True,\n",
    "\n",
    "    # Create virtual Processes and Flows\n",
    "    # Creates missing flows for Processes that have imbalance of input and output flows\n",
    "    # i.e. unreported flows\n",
    "    \"use_virtual_flows\": False,\n",
    "}\n",
    "\n",
    "# *********************************************************************************\n",
    "# * Step 2: Load the data from Excel file using model_parameters and DataProvider *\n",
    "# *********************************************************************************\n",
    "print(\"DataProvider: Reading data from file '{}'...\".format(model_params[\"filename\"]))\n",
    "dataprovider = DataProvider(model_params)\n",
    "\n",
    "# **********************************************************\n",
    "# * Step 3: Check data integrity and build flow graph data *\n",
    "# **********************************************************\n",
    "print(\"Checking data integrity, detecting year range from file: {}\".format(model_params[\"detect_year_range\"]))\n",
    "checker = DataChecker(dataprovider)\n",
    "default_detect_year_range = model_params[\"detect_year_range\"]\n",
    "flowsolver_data = checker.build_flowsolver_data(model_params[\"year_start\"], model_params[\"year_end\"], detect_year_range=default_detect_year_range)\n",
    "is_checker_ok, checker_messages = checker.check_for_errors()\n",
    "\n",
    "# Something went wrong with DataChecker, show error messages and stop execution\n",
    "if not is_checker_ok:\n",
    "    for msg in checker_messages:\n",
    "        print(msg)\n",
    "    SystemExit(-1)\n",
    "\n",
    "# Get the updated years from graph_data\n",
    "years = flowsolver_data[\"years\"]\n",
    "print(\"Using year range {} - {}\".format(years[0], years[-1]))\n",
    "\n",
    "# *******************************************************************\n",
    "# * Step 4: Solve flows for all timesteps using aiphoria FlowSolver *\n",
    "# *******************************************************************\n",
    "flowsolver = FlowSolver(flowsolver_data, use_virtual_flows=model_params[\"use_virtual_flows\"])\n",
    "flowsolver.solve_timesteps()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T05:34:17.216818900Z",
     "start_time": "2024-06-21T05:34:17.155700600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                    Description Dimension  \\\nAspect                                      \nTime        Model aspect \"time\"      Time   \nElement  Model aspect \"Element\"   Element   \n\n                                            Classification IndexLetter  \nAspect                                                                  \nTime     <ODYM_Classes.Classification object at 0x00000...           t  \nElement  <ODYM_Classes.Classification object at 0x00000...           e  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Description</th>\n      <th>Dimension</th>\n      <th>Classification</th>\n      <th>IndexLetter</th>\n    </tr>\n    <tr>\n      <th>Aspect</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Time</th>\n      <td>Model aspect \"time\"</td>\n      <td>Time</td>\n      <td>&lt;ODYM_Classes.Classification object at 0x00000...</td>\n      <td>t</td>\n    </tr>\n    <tr>\n      <th>Element</th>\n      <td>Model aspect \"Element\"</td>\n      <td>Element</td>\n      <td>&lt;ODYM_Classes.Classification object at 0x00000...</td>\n      <td>e</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ***************************\n",
    "# * Step 5: Initialize ODYM *\n",
    "# ***************************\n",
    "\n",
    "# Track solid wood equivalent and carbon. Dictionary of classifications enters the index table defined for the system. The index table lists all aspects needed and assigns a classification and index letter to each aspect.\n",
    "model_classifications = {\n",
    "    'Time': msc.Classification(Name='Time', Dimension='Time', ID=1, Items=years),\n",
    "    'Element': msc.Classification(Name='Elements', Dimension='Element', ID=2, Items=['Solid wood equivalent', 'Carbon']),\n",
    "}\n",
    "\n",
    "\n",
    "# Get model time start, end, and duration:\n",
    "model_time_start = int(min(model_classifications['Time'].Items))\n",
    "model_time_end = int(max(model_classifications['Time'].Items))\n",
    "model_duration = model_time_end - model_time_start\n",
    "\n",
    "index_table = pd.DataFrame({'Aspect': ['Time', 'Element'],  # 'Time' and 'Element' must be present!\n",
    "                            'Description': ['Model aspect \"time\"', 'Model aspect \"Element\"'],\n",
    "                            'Dimension': ['Time', 'Element'],  # 'Time' and 'Element' are also dimensions\n",
    "                            'Classification': [model_classifications[Aspect] for Aspect in ['Time', 'Element']],\n",
    "                            'IndexLetter': ['t', 'e' ]})  # Unique one letter (upper or lower case) indices to be used later for calculations.\n",
    "\n",
    "index_table.set_index('Aspect', inplace=True)  # Default indexing of IndexTable, other indices are produced on the fly\n",
    "index_table"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T05:34:18.378655600Z",
     "start_time": "2024-06-21T05:34:18.337426800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# **************************************\n",
    "# * Step 6: Initialize ODYM MFA system *\n",
    "# **************************************\n",
    "mfa_system = msc.MFAsystem(Name='Wood product system', Geogr_Scope='Europe', Unit='Mm3',\n",
    "                           ProcessList=[], FlowDict={}, StockDict={}, ParameterDict={},\n",
    "                           Time_Start=model_time_start, Time_End=model_time_end, IndexTable=index_table,\n",
    "                           Elements=index_table.loc['Element'].Classification.Items)\n",
    "\n",
    "# Get inflow values to stock\n",
    "year_index_to_year = dict(enumerate(years))\n",
    "unique_processes = flowsolver.get_unique_processes()\n",
    "unique_flows = flowsolver.get_unique_flows()\n",
    "\n",
    "# DataFrames for Processes, Flows and Flow values\n",
    "df_processes = flowsolver.get_processes_as_dataframe()\n",
    "df_flows = flowsolver.get_flows_as_dataframe()\n",
    "df_flow_values = flowsolver.get_evaluated_flow_values_as_dataframe()\n",
    "\n",
    "# Create ODYM objects\n",
    "odym_processes = []\n",
    "process_id_to_index = {}\n",
    "for process_id, process in flowsolver.get_unique_processes().items():\n",
    "    process_index = len(odym_processes)\n",
    "    process_id_to_index[process_id] = process_index\n",
    "    new_process = msc.Process(ID=process_index, Name=process.name)\n",
    "    odym_processes.append(new_process)\n",
    "\n",
    "odym_flows = {}\n",
    "for flow_id, flow in unique_flows.items():\n",
    "    source_process_index = process_id_to_index[flow.source_process_id]\n",
    "    target_process_index = process_id_to_index[flow.target_process_id]\n",
    "    new_flow = msc.Flow(ID=flow.id, P_Start=source_process_index, P_End=target_process_index, Indices='t,e', Values=None)\n",
    "    odym_flows[flow.id] = new_flow\n",
    "\n",
    "odym_stocks = {}\n",
    "for stock in flowsolver.get_all_stocks():\n",
    "    process_index = process_id_to_index[stock.id]\n",
    "    new_stock = msc.Stock(ID=stock.id, Name=stock.name, P_Res=process_index, Indices='t,e', Type=1, Values=None)\n",
    "    odym_stocks[stock.id] = new_stock\n",
    "\n",
    "mfa_system.ProcessList = odym_processes\n",
    "mfa_system.FlowDict = odym_flows\n",
    "mfa_system.StockDict = odym_stocks\n",
    "mfa_system.Initialize_FlowValues()\n",
    "mfa_system.Initialize_StockValues()\n",
    "mfa_system.Consistency_Check()\n",
    "\n",
    "# Update ODYM flow values from flow values DataFrame\n",
    "for flow_id, flow in mfa_system.FlowDict.items():\n",
    "    for year_index, value in enumerate(flow.Values):\n",
    "        # NOTE: Virtual flows use default value defined in Flow for carbon content (now 1.0)\n",
    "        solved_flow = flowsolver.get_flow(year=year_index_to_year[year_index], flow_id=flow_id)\n",
    "        flow.Values[year_index, 0] = solved_flow.evaluated_value\n",
    "        flow.Values[year_index, 1] = solved_flow.evaluated_value_carbon\n",
    "\n",
    "# Refer to Pandas for more instructions on how to save DataFrame to file:\n",
    "# Example: df.to_excel(\"filename.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T05:34:18.967447700Z",
     "start_time": "2024-06-21T05:34:18.919337100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mass balance shape (timesteps x processes x chemical elements): (2, 7, 2)\n",
      "Mass balance by Process, sum of all years\n",
      "  Process  Mass balance\n",
      "0      P1           6.0\n",
      "1      P2           3.0\n",
      "2      P3           3.0\n",
      "3      P4           0.0\n",
      "4      P5           0.0\n",
      "5      P2           3.0\n",
      "6      P2           3.0\n"
     ]
    }
   ],
   "source": [
    "# *****************************************\n",
    "# * Step 7: Show mass balance information *\n",
    "# *****************************************\n",
    "\n",
    "# Get mass balance from MFA system\n",
    "mb = mfa_system.MassBalance()\n",
    "sum_mb = np.abs(mb).sum(axis=0).sum(axis=1) # reports the sum of all absolute balancing errors by process for all years.\n",
    "print(\"Mass balance shape (timesteps x processes x chemical elements): {}\".format(mb.shape))\n",
    "\n",
    "# Show process mass balances based, all years\n",
    "print(\"Mass balance by Process, sum of all years\")\n",
    "cols = {\"Process\": [], \"Mass balance\": []}\n",
    "for process_index, process_mass_balance in enumerate(sum_mb):\n",
    "    process_name = odym_processes[process_index].Name\n",
    "    cols[\"Process\"].append(process_name)\n",
    "    cols[\"Mass balance\"].append(process_mass_balance)\n",
    "\n",
    "df_mass_balances = pd.DataFrame(cols)\n",
    "print(df_mass_balances)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T05:34:19.554058400Z",
     "start_time": "2024-06-21T05:34:19.538455600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# **************************************\n",
    "# * Step 8: Create ODYM dynamic stocks *\n",
    "# **************************************\n",
    "\n",
    "# Convert flowgraph stocks to ODYM stocks\n",
    "\n",
    "# Stock ID to Dynamic Stock model that tracks\n",
    "stock_id_to_dsm_swe = {}\n",
    "stock_id_to_dsm_carbon = {}\n",
    "for stock in flowsolver.get_all_stocks():\n",
    "    total_inflows_swe = []\n",
    "    total_inflows_carbon = []\n",
    "\n",
    "    # Gather values for all years\n",
    "    for year in years:\n",
    "        year_inflows_swe = flowsolver.get_process_inflows_total_swe(stock.id, year)\n",
    "        year_inflows_carbon = flowsolver.get_process_outflows_total_carbon(stock.id, year)\n",
    "        total_inflows_swe.append(year_inflows_swe)\n",
    "        total_inflows_carbon.append(year_inflows_carbon)\n",
    "\n",
    "    stock_lifetime_params = {\n",
    "        'Type': stock.distribution_type,\n",
    "        'Mean': [stock.lifetime],\n",
    "        'StdDev': [stock.distribution_params]\n",
    "    }\n",
    "\n",
    "    dsm_swe = dsm.DynamicStockModel(t=np.array(years), i=total_inflows_swe, lt=stock_lifetime_params)\n",
    "    stock_id_to_dsm_swe[stock.id] = dsm_swe\n",
    "\n",
    "    dsm_carbon = dsm.DynamicStockModel(t=np.array(years), i=total_inflows_carbon, lt=stock_lifetime_params)\n",
    "    stock_id_to_dsm_carbon[stock.id] = dsm_carbon"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T05:34:20.194346400Z",
     "start_time": "2024-06-21T05:34:20.165399100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# ******************************************\n",
    "# * Step 9: Visualize dynamic stock values *\n",
    "# ******************************************\n",
    "\n",
    "# Make graphs for each dynamic stock models that track Solid wood Equivalent value\n",
    "num_years = len(years) + 1\n",
    "range_x_ticks = range(min(years), max(years) + 1)\n",
    "for stock_id in stock_id_to_dsm_swe.keys():\n",
    "    # SWE Stock\n",
    "    dsm_swe = stock_id_to_dsm_swe[stock_id]\n",
    "    swe_stock_by_cohort = dsm_swe.compute_s_c_inflow_driven()\n",
    "    swe_oc = dsm_swe.compute_o_c_from_s_c()\n",
    "    swe_s_c = dsm_swe.compute_s_c_inflow_driven()\n",
    "    swe_stock_total = dsm_swe.compute_stock_total()\n",
    "    swe_stock_change = dsm_swe.compute_stock_change()\n",
    "    swe_o = dsm_swe.compute_outflow_total()\n",
    "\n",
    "    # Carbon stock\n",
    "    dsm_carbon = stock_id_to_dsm_carbon[stock_id]\n",
    "    carbon_stock_by_cohort = dsm_carbon.compute_s_c_inflow_driven()\n",
    "    carbon_oc = dsm_carbon.compute_o_c_from_s_c()\n",
    "    carbon_s_c = dsm_carbon.compute_s_c_inflow_driven()\n",
    "    carbon_stock_total = dsm_carbon.compute_stock_total()\n",
    "    carbon_stock_change = dsm_carbon.compute_stock_change()\n",
    "    carbon_o = dsm_carbon.compute_outflow_total()\n",
    "\n",
    "    # Create 4 horizontal subplots:\n",
    "    # SWE stock total, SWE stock change, Carbon stock total, Carbon stock change\n",
    "    fig, axes = plt.subplots(1, 4, sharex='all', sharey='all', figsize=(20, 8))\n",
    "    title_size = 8\n",
    "\n",
    "    # SWE Stock total (in-use stocks)\n",
    "    swe_bar_total = axes[0].bar(years, swe_stock_total)\n",
    "    axes[0].set_xticks(range_x_ticks)\n",
    "    axes[0].set_xlabel(\"Year\")\n",
    "    axes[0].set_ylabel(\"In-use stock\")\n",
    "    axes[0].set_title(\"\")\n",
    "    axes[0].set_title(\"{}\".format(stock_id + \", SWE in-use stock per year\"))\n",
    "    axes[0].title.set_size(title_size)\n",
    "\n",
    "    # SWE Stock change\n",
    "    swe_bar_change = axes[1].bar(years, swe_stock_change)\n",
    "    axes[1].set_xticks(range_x_ticks)\n",
    "    axes[1].set_xlabel(\"Year\")\n",
    "    axes[1].set_ylabel(\"Stock change\")\n",
    "    axes[1].set_title(\"\")\n",
    "    axes[1].set_title(\"{}\".format(stock_id + \", SWE stock change per year\"))\n",
    "    axes[1].title.set_size(title_size)\n",
    "\n",
    "    # Carbon Stock total (in-use stocks)\n",
    "    carbon_bar_total = axes[2].bar(years, carbon_stock_total)\n",
    "    axes[2].set_xticks(range_x_ticks)\n",
    "    axes[2].set_xlabel(\"Year\")\n",
    "    axes[2].set_ylabel(\"In-use stock\")\n",
    "    axes[2].set_title(\"\")\n",
    "    axes[2].set_title(\"{}\".format(stock_id + \", Carbon in-use stock per year\"))\n",
    "    axes[2].title.set_size(title_size)\n",
    "\n",
    "    # Carbon Stock change\n",
    "    carbon_bar_change = axes[3].bar(years, carbon_stock_change)\n",
    "    axes[3].set_xticks(range_x_ticks)\n",
    "    axes[3].set_xlabel(\"Year\")\n",
    "    axes[3].set_ylabel(\"Stock change\")\n",
    "    axes[3].set_title(\"\")\n",
    "    axes[3].set_title(\"{}\".format(stock_id + \", Carbon stock change per year\"))\n",
    "    axes[3].title.set_size(title_size)\n",
    "\n",
    "    # Show values on top of SWE Stock total bar charts\n",
    "    y_offset_factor = 0.02\n",
    "    for rect in swe_bar_total:\n",
    "        offset_y = rect.axes.get_ylim()[1] * y_offset_factor\n",
    "        rect_x = rect.get_x()\n",
    "        rect_h = rect.get_height()\n",
    "        rect_w = rect.get_width()\n",
    "        rect_mid = rect_w / num_years\n",
    "        axes[0].text(rect_x + rect_mid, rect_h + offset_y, '{:.1f}'.format(rect_h))\n",
    "\n",
    "    # Show values on top of SWE Stock change bar charts\n",
    "    for rect in swe_bar_change:\n",
    "        offset_y = rect.axes.get_ylim()[1] * y_offset_factor\n",
    "        rect_x = rect.get_x()\n",
    "        rect_h = rect.get_height()\n",
    "        rect_w = rect.get_width()\n",
    "        rect_mid = rect_w / num_years\n",
    "        axes[1].text(rect_x + rect_mid, rect_h + offset_y, '{:.1f}'.format(rect_h))\n",
    "\n",
    "    # Show values on top of SWE Stock total bar charts\n",
    "    y_offset_factor = 0.02\n",
    "    for rect in carbon_bar_total:\n",
    "        offset_y = rect.axes.get_ylim()[1] * y_offset_factor\n",
    "        rect_x = rect.get_x()\n",
    "        rect_h = rect.get_height()\n",
    "        rect_w = rect.get_width()\n",
    "        rect_mid = rect_w / num_years\n",
    "        axes[2].text(rect_x + rect_mid, rect_h + offset_y, '{:.1f}'.format(rect_h))\n",
    "\n",
    "    # Show values on top of SWE Stock change bar charts\n",
    "    for rect in carbon_bar_change:\n",
    "        offset_y = rect.axes.get_ylim()[1] * y_offset_factor\n",
    "        rect_x = rect.get_x()\n",
    "        rect_h = rect.get_height()\n",
    "        rect_w = rect.get_width()\n",
    "        rect_mid = rect_w / num_years\n",
    "        axes[3].text(rect_x + rect_mid, rect_h + offset_y, '{:.1f}'.format(rect_h))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T05:34:20.728317700Z",
     "start_time": "2024-06-21T05:34:20.721791900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# *****************************************************\n",
    "# * Step 10: Visualize the flow graph as Sankey graph *\n",
    "# *****************************************************\n",
    "\n",
    "# Color mappings\n",
    "process_transformation_stage_colors = dict()\n",
    "process_transformation_stage_colors[\"Source\"] = \"#7DDA60\"\n",
    "process_transformation_stage_colors[\"First\"] = \"#eb5e34\"\n",
    "process_transformation_stage_colors[\"Second\"] = \"#8c76cf\"\n",
    "process_transformation_stage_colors[\"Third\"] = \"#5BAA11\"\n",
    "process_transformation_stage_colors[\"VAM\"] = \"#3281db\"\n",
    "process_transformation_stage_colors[\"RoW\"] = \"#61b053\"  # Rest of the world\n",
    "process_transformation_stage_colors[\"EoL\"] = \"#EFC3CA\"  # Brown\n",
    "process_transformation_stage_colors[\"by_prod\"] = \"#DFC57B\"  # gold\n",
    "process_transformation_stage_colors[\"Virtual\"] = \"#707070\"\n",
    "\n",
    "#\n",
    "virtual_process_graph_labels = dict()\n",
    "virtual_process_graph_labels[\"VP_P2:EU\"] = \"Unreported flow from P2\"\n",
    "virtual_process_graph_labels[\"VP_P3:EU\"] = \"Unreported flow from P3\"\n",
    "\n",
    "# Virtual Process and virtual Flow colors\n",
    "visualizer_params = {\n",
    "    # User can hide processes in Sankey graph that have total inflows less than this value\n",
    "    # This value cannot be changed now in the Sankey graph\n",
    "    \"small_node_threshold\": 5,\n",
    "\n",
    "    # Dictionary to define labels for virtual flows\n",
    "    # If dictionary contains label for the virtual process then that is used,\n",
    "    # otherwise the virtual process ID is used\n",
    "    \"virtual_process_graph_labels\": virtual_process_graph_labels,\n",
    "\n",
    "    # Dictionary to define color of process by the process transformation stage name\n",
    "    # All must be provided as a RGB hex string, prefixed by character '#'\n",
    "    # Usage example: { \"Source\": \"#707070\" }\n",
    "    \"process_transformation_stage_colors\": process_transformation_stage_colors,\n",
    "\n",
    "    # How transparent flows are (0.0 = invisible, 1.0 = fully opaque)\n",
    "    \"flow_alpha\": 0.75,\n",
    "\n",
    "    # Color for virtual process\n",
    "    \"virtual_process_color\": \"rgba(0.3, 0.3, 0.3, 0.6)\",\n",
    "\n",
    "    # Color for virtual flows\n",
    "    \"virtual_flow_color\": \"rgba(0.5, 0.5, 0.5, 0.5)\",\n",
    "}\n",
    "\n",
    "visualizer = DataVisualizer()\n",
    "visualizer.build(flowsolver, visualizer_params)\n",
    "visualizer.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T05:34:23.342852300Z",
     "start_time": "2024-06-21T05:34:21.265940100Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
