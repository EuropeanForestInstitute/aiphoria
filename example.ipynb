{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataProvider: Reading data from file 'data/example_data.xlsx'...\n",
      "Checking data integrity, detecting year range from file: True\n",
      "Checking stock distribution types...\n",
      "Checking stock distribution parameters...\n",
      "Checking process total inflows and total outflows mismatches...\n",
      "Total inflows and total outflows for process 'P3:EU' does not match.\n",
      "Absolute difference of total inflows and total outflows was 1\n",
      "Check following inflows in Excel sheet 'Flows':\n",
      "- flow 'P2:EU P3:EU' in row 5\n",
      "Check following outflows:\n",
      "- flow 'P3:EU P5:EU' in row 7\n",
      "\n",
      "Total inflows and total outflows for process 'P3:EU' does not match.\n",
      "Absolute difference of total inflows and total outflows was 1\n",
      "Check following inflows in Excel sheet 'Flows':\n",
      "- flow 'P2:EU P3:EU' in row 14\n",
      "Check following outflows:\n",
      "- flow 'P3:EU P5:EU' in row 16\n",
      "\n",
      "Using year range 2021 - 2022\n",
      "Created 2 virtual processes and 2 virtual flows for year 2021\n",
      "\t- Virtual process ID 'VP_P2:EU'\n",
      "\t- Virtual process ID 'VP_P3:EU'\n",
      "\t- Virtual flow ID 'P2:EU VP_P2:EU'\n",
      "\t- Virtual flow ID 'P3:EU VP_P3:EU'\n",
      "\n",
      "Created 2 virtual processes and 2 virtual flows for year 2022\n",
      "\t- Virtual process ID 'VP_P2:EU'\n",
      "\t- Virtual process ID 'VP_P3:EU'\n",
      "\t- Virtual flow ID 'P2:EU VP_P2:EU'\n",
      "\t- Virtual flow ID 'P3:EU VP_P3:EU'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from core.dataprovider import DataProvider\n",
    "from core.datachecker import DataChecker\n",
    "from core.datavisualizer import DataVisualizer\n",
    "from core.flowgraph import FlowGraph\n",
    "\n",
    "# Path configuration\n",
    "MainPath = os.path.join('.')\n",
    "sys.path.insert(0, MainPath)\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '.', 'lib', 'odym', 'modules'))\n",
    "\n",
    "# ODYM classes\n",
    "import ODYM_Classes as msc\n",
    "import dynamic_stock_model as dsm\n",
    "\n",
    "# For Ipython Notebook only\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# **********************************************\n",
    "# * Step 1: Define parameters for the aiphoria *\n",
    "# **********************************************\n",
    "model_params = {\n",
    "    # Path (either relative or absolute) to the Excel file that contains the data for Processes and Flows\n",
    "    # Path to the Excel file that contains data for the Processes and Flows\n",
    "    # Path can be either:\n",
    "    #   relative path (e.g. \"/data/data.xlsx\") or\n",
    "    #   absolute path (e.g. \"C:\\aiphoria\\data\\data.xlsx\")\n",
    "    \"filename\": \"data/example_data.xlsx\",\n",
    "\n",
    "    # *************\n",
    "    # * Processes *\n",
    "    # *************\n",
    "    # Name of the sheet in Excel file that contains data for Processes\n",
    "    \"sheet_name_processes\": \"Processes\",\n",
    "\n",
    "    # Column range that contains data for the Processes\n",
    "    # The both starting and ending columns are included in the range\n",
    "    # (e.g. \"A:B\" means columns A, B, and C)\n",
    "    \"column_range_processes\": \"B:R\",\n",
    "\n",
    "    # First row number that contains Process data\n",
    "    # Lines are read until there is no rows with data anymore\n",
    "    # and empty lines are skipped\n",
    "    \"row_start_processes\":  3,\n",
    "\n",
    "\n",
    "    # *********\n",
    "    # * Flows *\n",
    "    # *********\n",
    "    # Name of the sheet in Excel file that contains data for Flows\n",
    "    \"sheet_name_flows\": \"Flows\",\n",
    "\n",
    "    # Column range that contains data for the Flows\n",
    "    # The both starting and ending columns are included in the range\n",
    "    # (e.g. \"A:B\" means columns A, B, and C)\n",
    "    \"column_range_flows\": \"B:O\",\n",
    "\n",
    "    # First row number that contains Flow data\n",
    "    # Lines are read until there is no rows with data anymore\n",
    "    # and empty lines are skipped\n",
    "    \"row_start_flows\": 3,\n",
    "\n",
    "\n",
    "    # ********************\n",
    "    # * Model parameters *\n",
    "    # ********************\n",
    "    # Starting year of the model, this needs to be found from the Excel file\n",
    "    \"year_start\": 2021,\n",
    "\n",
    "    # Ending year of the model, this can be extended as far as needed\n",
    "    # The last existing year data is copied to the non-existing years\n",
    "    # Last year is included in the time range\n",
    "    \"year_end\": 2021,\n",
    "\n",
    "    # Should the model detect year range automatically from file?\n",
    "    # True overrides year_start and year_end values\n",
    "    \"detect_year_range\": True,\n",
    "\n",
    "    # Create virtual Processes and Flows\n",
    "    # Creates missing flows for Processes that have imbalance of input and output flows\n",
    "    # i.e. unreported flows\n",
    "    \"use_virtual_flows\": True,\n",
    "}\n",
    "\n",
    "\n",
    "# *********************************************************************************\n",
    "# * Step 2: Load the data from Excel file using model_parameters and DataProvider *\n",
    "# *********************************************************************************\n",
    "print(\"DataProvider: Reading data from file '{}'...\".format(model_params[\"filename\"]))\n",
    "dataprovider = DataProvider(model_params)\n",
    "\n",
    "# **********************************************************\n",
    "# * Step 3: Check data integrity and build flow graph data *\n",
    "# **********************************************************\n",
    "print(\"Checking data integrity, detecting year range from file: {}\".format(model_params[\"detect_year_range\"]))\n",
    "checker = DataChecker(dataprovider)\n",
    "default_detect_year_range = model_params[\"detect_year_range\"]\n",
    "flowgraph_data = checker.build_flowgraph_data(model_params[\"year_start\"], model_params[\"year_end\"], detect_year_range=default_detect_year_range)\n",
    "is_checker_ok, checker_messages = checker.check_for_errors()\n",
    "\n",
    "# Something went wrong with DataChecker, show error messages and stop execution\n",
    "if not is_checker_ok:\n",
    "    for msg in checker_messages:\n",
    "        print(msg)\n",
    "    SystemExit(-1)\n",
    "\n",
    "# Get the updated years from graph_data\n",
    "years = flowgraph_data[\"years\"]\n",
    "print(\"Using year range {} - {}\".format(years[0], years[-1]))\n",
    "\n",
    "# ****************************************************\n",
    "# * Step 4: Build flow graph and solve all timesteps *\n",
    "# ****************************************************\n",
    "flowgraph = FlowGraph(flowgraph_data, use_virtual_flows=model_params[\"use_virtual_flows\"])\n",
    "flowgraph.solve_timesteps()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T13:48:21.160638100Z",
     "start_time": "2024-05-30T13:48:19.658733Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                    Description Dimension  \\\nAspect                                      \nTime        Model aspect \"time\"      Time   \nElement  Model aspect \"Element\"   Element   \n\n                                            Classification IndexLetter  \nAspect                                                                  \nTime     <ODYM_Classes.Classification object at 0x00000...           t  \nElement  <ODYM_Classes.Classification object at 0x00000...           e  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Description</th>\n      <th>Dimension</th>\n      <th>Classification</th>\n      <th>IndexLetter</th>\n    </tr>\n    <tr>\n      <th>Aspect</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Time</th>\n      <td>Model aspect \"time\"</td>\n      <td>Time</td>\n      <td>&lt;ODYM_Classes.Classification object at 0x00000...</td>\n      <td>t</td>\n    </tr>\n    <tr>\n      <th>Element</th>\n      <td>Model aspect \"Element\"</td>\n      <td>Element</td>\n      <td>&lt;ODYM_Classes.Classification object at 0x00000...</td>\n      <td>e</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ***************************\n",
    "# * Step 5: Initialize ODYM *\n",
    "# ***************************\n",
    "\n",
    "# Track only 1 element: carbon. Dictionary of classifications enters the index table defined for the system. The index table lists all aspects needed and assigns a classification and index letter to each aspect.\n",
    "model = {\n",
    "    'Time': msc.Classification(Name='Time', Dimension='Time', ID=1, Items=years),\n",
    "    'Element': msc.Classification(Name='Elements', Dimension='Element', ID=2, Items=['C']),\n",
    "}\n",
    "\n",
    "\n",
    "# Get model time start, end, and duration:\n",
    "model_time_start = int(min(model['Time'].Items))\n",
    "model_time_end = int(max(model['Time'].Items))\n",
    "model_duration = model_time_end - model_time_start\n",
    "\n",
    "index_table = pd.DataFrame({'Aspect': ['Time', 'Element'],  # 'Time' and 'Element' must be present!\n",
    "                            'Description': ['Model aspect \"time\"', 'Model aspect \"Element\"'],\n",
    "                            'Dimension': ['Time', 'Element'],  # 'Time' and 'Element' are also dimensions\n",
    "                            'Classification': [model[Aspect] for Aspect in ['Time', 'Element']],\n",
    "                            'IndexLetter': ['t', 'e']})  # Unique one letter (upper or lower case) indices to be used later for calculations.\n",
    "\n",
    "index_table.set_index('Aspect', inplace=True)  # Default indexing of IndexTable, other indices are produced on the fly\n",
    "index_table"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T13:48:21.176251800Z",
     "start_time": "2024-05-30T13:48:21.160638100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# **************************************\n",
    "# * Step 6: Initialize ODYM MFA system *\n",
    "# **************************************\n",
    "mfa_system = msc.MFAsystem(Name='Wood product system', Geogr_Scope='Europe', Unit='Mm3',\n",
    "                           ProcessList=[], FlowDict={}, StockDict={}, ParameterDict={},\n",
    "                           Time_Start=model_time_start, Time_End=model_time_end, IndexTable=index_table,\n",
    "                           Elements=index_table.loc['Element'].Classification.Items)\n",
    "\n",
    "# Get inflow values to stock\n",
    "year_index_to_year = dict(enumerate(years))\n",
    "unique_processes = flowgraph.get_unique_processes()\n",
    "unique_flows = flowgraph.get_unique_flows()\n",
    "\n",
    "# Create ODYM objects\n",
    "odym_processes = []\n",
    "process_id_to_index = {}\n",
    "for process_id, process in flowgraph.get_unique_processes().items():\n",
    "    process_index = len(odym_processes)\n",
    "    process_id_to_index[process_id] = process_index\n",
    "    new_process = msc.Process(ID=process_index, Name=process.name)\n",
    "    odym_processes.append(new_process)\n",
    "\n",
    "odym_flows = {}\n",
    "for flow_id, flow in unique_flows.items():\n",
    "    source_process_index = process_id_to_index[flow.source_process_id]\n",
    "    target_process_index = process_id_to_index[flow.target_process_id]\n",
    "    new_flow = msc.Flow(ID=flow.id, P_Start=source_process_index, P_End=target_process_index, Indices='t,e', Values=None)\n",
    "    odym_flows[flow.id] = new_flow\n",
    "\n",
    "odym_stocks = {}\n",
    "for stock in flowgraph.get_all_stocks():\n",
    "    process_index = process_id_to_index[stock.id]\n",
    "    new_stock = msc.Stock(ID=stock.id, Name=stock.name, P_Res=process_index, Indices='t,e', Type=1, Values=None)\n",
    "    odym_stocks[stock.id] = new_stock\n",
    "\n",
    "mfa_system.ProcessList = odym_processes\n",
    "mfa_system.FlowDict = odym_flows\n",
    "mfa_system.StockDict = odym_stocks\n",
    "mfa_system.Initialize_FlowValues()\n",
    "mfa_system.Initialize_StockValues()\n",
    "mfa_system.Consistency_Check()\n",
    "\n",
    "# Update ODYM flow values from flow values DataFrame\n",
    "df_flow_values = flowgraph.get_evaluated_flow_values_as_dataframe()\n",
    "for flow_id, flow in mfa_system.FlowDict.items():\n",
    "    for year_index, value in enumerate(flow.Values):\n",
    "        flow_value = df_flow_values.at[year_index_to_year[year_index], flow_id]\n",
    "        flow.Values[year_index] = flow_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T13:48:21.314335300Z",
     "start_time": "2024-05-30T13:48:21.176251800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mass balance shape (timesteps x processes x chemical elements): (2, 9, 1)\n",
      "Mass balance by Process, sum of all years\n",
      "  Process  Mass balance\n",
      "0      P1           4.0\n",
      "1      P2           0.0\n",
      "2      P3           0.0\n",
      "3      P4           0.0\n",
      "4      P5           0.0\n",
      "5      P2           2.0\n",
      "6      P2           2.0\n",
      "7   VP_P2           2.0\n",
      "8   VP_P3           2.0\n"
     ]
    }
   ],
   "source": [
    "# *****************************************\n",
    "# * Step 7: Show mass balance information *\n",
    "# *****************************************\n",
    "\n",
    "# Get mass balance from MFA system\n",
    "mb = mfa_system.MassBalance()\n",
    "sum_mb = np.abs(mb).sum(axis=0).sum(axis=1) # reports the sum of all absolute balancing errors by process for all years.\n",
    "print(\"Mass balance shape (timesteps x processes x chemical elements): {}\".format(mb.shape))\n",
    "\n",
    "# Show process mass balances based, all years\n",
    "print(\"Mass balance by Process, sum of all years\")\n",
    "cols = {\"Process\": [], \"Mass balance\": []}\n",
    "for process_index, process_mass_balance in enumerate(sum_mb):\n",
    "    process_name = odym_processes[process_index].Name\n",
    "    cols[\"Process\"].append(process_name)\n",
    "    cols[\"Mass balance\"].append(process_mass_balance)\n",
    "\n",
    "df_mass_balances = pd.DataFrame(cols)\n",
    "print(df_mass_balances)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T13:48:21.314335300Z",
     "start_time": "2024-05-30T13:48:21.298689900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# **************************************\n",
    "# * Step 8: Create ODYM dynamic stocks *\n",
    "# **************************************\n",
    "\n",
    "# Convert flowgraph stocks to ODYM stocks\n",
    "stock_id_to_dsm = {}\n",
    "for stock in flowgraph.get_all_stocks():\n",
    "    total_inflow_values = []\n",
    "    for year in years:\n",
    "        year_inflows = flowgraph.get_process_inflows_total(stock.id, year)\n",
    "        total_inflow_values.append(year_inflows)\n",
    "\n",
    "    stock_lifetime_params = {\n",
    "        'Type': stock.distribution_type,\n",
    "        'Mean': [stock.lifetime],\n",
    "        'StdDev': [stock.distribution_params]\n",
    "    }\n",
    "\n",
    "    new_dsm = dsm.DynamicStockModel(t=np.array(years), i=total_inflow_values, lt=stock_lifetime_params)\n",
    "    stock_id_to_dsm[stock.id] = new_dsm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T13:48:21.329965900Z",
     "start_time": "2024-05-30T13:48:21.314335300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# ******************************************\n",
    "# * Step 9: Visualize dynamic stock values *\n",
    "# ******************************************\n",
    "\n",
    "# Make graphs for each dynamic stock models\n",
    "for stock_id, dyn_stock in stock_id_to_dsm.items():\n",
    "    stock_by_cohort = dyn_stock.compute_s_c_inflow_driven()\n",
    "    oc = dyn_stock.compute_o_c_from_s_c()\n",
    "    s_c = dyn_stock.compute_s_c_inflow_driven()\n",
    "    stock_total = dyn_stock.compute_stock_total()\n",
    "    stock_change = dyn_stock.compute_stock_change()\n",
    "    o = dyn_stock.compute_outflow_total()\n",
    "\n",
    "    # Create 2 horizontal subplots\n",
    "    fig, axes = plt.subplots(1, 2, sharex='all', sharey='all', figsize=(20, 8))\n",
    "\n",
    "    # Stock total (in-use stocks)\n",
    "    bar_total = axes[0].bar(years, stock_total)\n",
    "    axes[0].set_xticks(range(min(years), max(years) + 1))\n",
    "    axes[0].set_xlabel(\"Year\")\n",
    "    axes[0].set_ylabel(\"In-use stock\")\n",
    "    axes[0].set_title(\"\")\n",
    "    axes[0].set_title(\"{}\".format(stock_id + \", in-use stock per year\"))\n",
    "\n",
    "    # Stock change\n",
    "    bar_change = axes[1].bar(years, stock_change)\n",
    "    axes[1].set_xticks(range(min(years), max(years) + 1))\n",
    "    axes[1].set_xlabel(\"Year\")\n",
    "    axes[1].set_ylabel(\"Stock change\")\n",
    "    axes[1].set_title(\"\")\n",
    "    axes[1].set_title(\"{}\".format(stock_id + \", stock change per year\"))\n",
    "\n",
    "    # Display values on top of bar charts (total)\n",
    "    for rect in bar_total:\n",
    "        rect_x = rect.get_x()\n",
    "        rect_h = rect.get_height()\n",
    "        rect_w = rect.get_width()\n",
    "        rect_mid = rect_w / 6\n",
    "        axes[0].text(rect_x + rect_mid, rect_h + 10, '{:.1f}'.format(rect_h))\n",
    "\n",
    "    # Display values on top of bar charts (change)\n",
    "    for rect in bar_change:\n",
    "        rect_x = rect.get_x()\n",
    "        rect_h = rect.get_height()\n",
    "        rect_w = rect.get_width()\n",
    "        rect_mid = rect_w / 6\n",
    "        axes[1].text(rect_x + rect_mid, rect_h + 10, '{:.1f}'.format(rect_h))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T13:48:21.392456Z",
     "start_time": "2024-05-30T13:48:21.329965900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# *****************************************************\n",
    "# * Step 10: Visualize the flow graph as Sankey graph *\n",
    "# *****************************************************\n",
    "\n",
    "# Color mappings\n",
    "process_transformation_stage_colors = dict()\n",
    "process_transformation_stage_colors[\"Source\"] = \"#7DDA60\"\n",
    "process_transformation_stage_colors[\"First\"] = \"#eb5e34\"\n",
    "process_transformation_stage_colors[\"Second\"] = \"#8c76cf\"\n",
    "process_transformation_stage_colors[\"Third\"] = \"#5BAA11\"\n",
    "process_transformation_stage_colors[\"VAM\"] = \"#3281db\"\n",
    "process_transformation_stage_colors[\"RoW\"] = \"#61b053\"  # Rest of the world\n",
    "process_transformation_stage_colors[\"EoL\"] = \"#EFC3CA\"  # Brown\n",
    "process_transformation_stage_colors[\"by_prod\"] = \"#DFC57B\"  # gold\n",
    "process_transformation_stage_colors[\"Virtual\"] = \"#707070\"\n",
    "\n",
    "#\n",
    "virtual_process_graph_labels = dict()\n",
    "virtual_process_graph_labels[\"VP_P2:EU\"] = \"Unreported flow from P2\"\n",
    "virtual_process_graph_labels[\"VP_P3:EU\"] = \"Unreported flow from P3\"\n",
    "\n",
    "# Virtual Process and virtual Flow colors\n",
    "visualizer_params = {\n",
    "    # User can hide processes in Sankey graph that have total inflows less than this value\n",
    "    # This value cannot be changed now in the Sankey graph\n",
    "    \"small_node_threshold\": 5,\n",
    "\n",
    "    # Dictionary to define labels for virtual flows\n",
    "    # If dictionary contains label for the virtual process then that is used,\n",
    "    # otherwise the virtual process ID is used\n",
    "    \"virtual_process_graph_labels\": virtual_process_graph_labels,\n",
    "\n",
    "    # Dictionary to define color of process by the process transformation stage name\n",
    "    # All must be provided as a RGB hex string, prefixed by character '#'\n",
    "    # Usage example: { \"Source\": \"#707070\" }\n",
    "    \"process_transformation_stage_colors\": process_transformation_stage_colors,\n",
    "\n",
    "    # How transparent flows are (0.0 = invisible, 1.0 = fully opaque)\n",
    "    \"flow_alpha\": 0.75,\n",
    "\n",
    "    # Color for virtual process\n",
    "    \"virtual_process_color\": \"rgba(0.3, 0.3, 0.3, 0.6)\",\n",
    "\n",
    "    # Color for virtual flows\n",
    "    \"virtual_flow_color\": \"rgba(0.5, 0.5, 0.5, 0.5)\",\n",
    "}\n",
    "\n",
    "visualizer = DataVisualizer()\n",
    "visualizer.build(flowgraph, visualizer_params)\n",
    "visualizer.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T13:48:23.771534200Z",
     "start_time": "2024-05-30T13:48:21.345591100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T13:48:23.772535300Z",
     "start_time": "2024-05-30T13:48:23.748724600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
