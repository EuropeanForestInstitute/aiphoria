{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# *****************************************************\n",
    "# * Import required packages and set up path for ODYM *\n",
    "# *****************************************************\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from core.dataprovider import DataProvider\n",
    "from core.datachecker import DataChecker\n",
    "from core.datavisualizer import DataVisualizer\n",
    "from core.network_graph import NetworkGraph\n",
    "from core.flowsolver import FlowSolver\n",
    "from core.parameters import ParameterName\n",
    "from core.utils import setup_current_working_directory, setup_odym_directories, create_output_directory, \\\n",
    "    setup_scenario_output_directories, \\\n",
    "    calculate_scenario_mass_balance, build_mfa_system_for_scenario, shorten_sheet_name,\\\n",
    "    show_exception_errors, show_model_parameters\n",
    "\n",
    "# NOTE: These needs to be called before importing ODYM classes\n",
    "setup_current_working_directory()\n",
    "setup_odym_directories()\n",
    "create_output_directory(os.path.join(os.getcwd(), \"output\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ******************************************************\n",
    "# * Step 1: Load the data from Excel file DataProvider *\n",
    "# ******************************************************\n",
    "\n",
    "# Load data from file using the DataProvider\n",
    "# and get model parameters from the file\n",
    "filename = \"data/example_data.xlsx\"\n",
    "\n",
    "\n",
    "print(\"Loading data from file {}...\".format(filename))\n",
    "dataprovider = None\n",
    "try:\n",
    "    dataprovider = DataProvider(filename)\n",
    "except Exception as ex:\n",
    "    show_exception_errors(ex, \"Following errors occurred when loading settings file:\")\n",
    "    print(\"Fatal error, stopping execution...\")\n",
    "    raise ex\n",
    "\n",
    "# Model parameters is a Dictionary that contains loaded data from Excel sheet named \"Settings\"\n",
    "# and are used for running the FlowSolver and setting up ODYM\n",
    "model_params = dataprovider.get_model_params()\n",
    "show_model_parameters(model_params)\n",
    "\n",
    "# Setup output path\n",
    "# NOTE: This only works inside Notebook, executable might need __file__?\n",
    "# Convert output directory name to absolute path and update model parameter dictionary\n",
    "model_params[ParameterName.OutputPath] = os.path.abspath(\n",
    "    os.path.join(os.getcwd(), model_params[ParameterName.OutputPath]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# **************************************************************\n",
    "# * Step 2: Check data integrity and build data for FlowSolver *\n",
    "# **************************************************************\n",
    "\n",
    "print(\"Checking errors in data...\")\n",
    "data_checker = DataChecker(dataprovider)\n",
    "\n",
    "# Build scenarios\n",
    "scenarios = []\n",
    "try:\n",
    "    scenarios = data_checker.build_scenarios()\n",
    "except Exception as ex:\n",
    "    show_exception_errors(ex, \"Following errors occurred when building scenarios:\")\n",
    "    print(\"Fatal error, stopping execution...\")\n",
    "    raise ex\n",
    "\n",
    "# Check for build scenario errors\n",
    "try:\n",
    "    data_checker.check_for_errors()\n",
    "except Exception as ex:\n",
    "    show_exception_errors(ex, \"Following errors found when checking scenario errors:\")\n",
    "    print(\"Fatal error, stopping execution...\")\n",
    "    raise ex\n",
    "\n",
    "# Create network graph for data\n",
    "# scenarios[0] is always the baseline scenario and is guaranteed to exist\n",
    "if model_params[ParameterName.CreateNetworkGraphs]:\n",
    "    network_visualizer = NetworkGraph()\n",
    "    network_visualizer.build(scenarios[0].scenario_data)\n",
    "    network_visualizer.show(os.path.join(model_params[ParameterName.OutputPath], \"network_graph.html\"))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ******************************************************************\n",
    "# * Step 3: Solve flows for baseline scenario using the FlowSolver *\n",
    "# ******************************************************************\n",
    "for scenario_index, scenario in enumerate(scenarios):\n",
    "    # NOTE: Baseline scenario is always the first element in the list\n",
    "    # and all the alternative scenarios (if any) are after that\n",
    "    if scenario_index == 0:\n",
    "        # Process baseline scenario\n",
    "        baseline_flow_solver = FlowSolver(scenario=scenario)\n",
    "        baseline_flow_solver.solve_timesteps()\n",
    "        scenario.flow_solver = baseline_flow_solver\n",
    "    else:\n",
    "        # Get and copy solved scenario data from baseline scenario flow solver\n",
    "        baseline_scenario_data = scenarios[0].flow_solver.get_solved_scenario_data()\n",
    "        scenario.copy_from_baseline_scenario_data(baseline_scenario_data)\n",
    "\n",
    "        # Solve this alternative scenario time steps\n",
    "        scenario_flow_solver = FlowSolver(scenario=scenario)\n",
    "        scenario_flow_solver.solve_timesteps()\n",
    "        scenario.flow_solver = scenario_flow_solver\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ****************************************************************************\n",
    "# * Step 4: Setup ODYM classifications and index table for each Scenario *\n",
    "# ****************************************************************************\n",
    "\n",
    "# Create output directory and scenario names as subdirectories. Deletes existing directory if needed.\n",
    "# NOTE: model_params[ParameterName.OutputPath] is absolute path\n",
    "scenario_name_to_output_path = setup_scenario_output_directories(\n",
    "    model_params[ParameterName.OutputPath],\n",
    "    [scenario.name for scenario in scenarios]\n",
    ")\n",
    "\n",
    "# Sheet names to what are written to file. Note that the order is important.\n",
    "sheet_names = [\"Processes\", \"Flows\", \"Flow values (baseline value)\", \"Mass balance\"]\n",
    "sheet_name_to_list_of_dfs = {name: [] for name in sheet_names}\n",
    "\n",
    "for scenario_index, scenario in enumerate(scenarios):\n",
    "    print(f\"Processing scenario '{scenario.name}' ({scenario_index + 1}/{len(scenarios)})...\")\n",
    "    # Build MFA system for the scenario\n",
    "    mfa_system = build_mfa_system_for_scenario(scenario)\n",
    "\n",
    "    # Processes Sheet\n",
    "    df_processes = scenario.flow_solver.get_processes_as_dataframe()\n",
    "    df_processes.insert(0, \"Scenario\", scenario.name)\n",
    "    sheet_name_to_list_of_dfs[sheet_names[0]].append(df_processes)\n",
    "\n",
    "    # Flows Sheet\n",
    "    df_flows = scenario.flow_solver.get_flows_as_dataframe()\n",
    "    df_flows.insert(0, \"Scenario\", scenario.name)\n",
    "    sheet_name_to_list_of_dfs[sheet_names[1]].append(df_flows)\n",
    "\n",
    "    # Flow values Sheet\n",
    "    df_flow_values = scenario.flow_solver.get_evaluated_flow_values_as_dataframe()\n",
    "    df_flow_values.insert(0, \"Scenario\", scenario.name)\n",
    "    sheet_name_to_list_of_dfs[sheet_names[2]].append(df_flow_values)\n",
    "\n",
    "    # Mass balance Sheet\n",
    "    df_scenario_mass_balance = calculate_scenario_mass_balance(mfa_system)\n",
    "    df_scenario_mass_balance.insert(0, \"Scenario\", scenario.name)\n",
    "    sheet_name_to_list_of_dfs[sheet_names[3]].append(df_scenario_mass_balance)\n",
    "\n",
    "# Combine all scenario data to one Excel file\n",
    "# by concatenating all sheet-specific list of DataFrames as one DataFrame\n",
    "combined_excel_filename = os.path.join(model_params[ParameterName.OutputPath], \"combined_scenario_data.xlsx\")\n",
    "print(f\"Exporting all scenarios to {combined_excel_filename}...\")\n",
    "with pd.ExcelWriter(combined_excel_filename) as writer:\n",
    "    for sheet_name, list_of_dfs in sheet_name_to_list_of_dfs.items():\n",
    "        df = pd.concat(list_of_dfs, ignore_index=True)\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"All scenario data exported to {combined_excel_filename}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ****************************************************************************\n",
    "# * Step 5: Build dynamic stock results for each Scenario and visualize *\n",
    "# ****************************************************************************\n",
    "\n",
    "print(\"Build dynamic stock results...\")\n",
    "for scenario in scenarios:\n",
    "    flow_solver = scenario.flow_solver\n",
    "    years = scenario.scenario_data.years\n",
    "    scenario_output_path = scenario_name_to_output_path[scenario.name]\n",
    "\n",
    "    # Full name of the baseline, e.g. \"Solid wood equivalent\"\n",
    "    baseline_value_name = scenario.scenario_data.baseline_value_name\n",
    "    baseline_unit_name = scenario.scenario_data.baseline_unit_name\n",
    "\n",
    "    # Total number of indicators\n",
    "    indicators = flow_solver.get_indicator_name_to_indicator()\n",
    "    num_indicators = len(indicators.keys())\n",
    "\n",
    "    # Baseline DSM\n",
    "    stock_id_to_baseline_dsm = flow_solver.get_baseline_dynamic_stocks()\n",
    "    stock_id_to_indicator_name_to_dsm = flow_solver.get_indicator_dynamic_stocks()\n",
    "\n",
    "    if not len(stock_id_to_baseline_dsm.keys()):\n",
    "        print(\"Scenario '{}': no dynamic stocks in the defined system\".format(scenario.name))\n",
    "        continue\n",
    "\n",
    "    # Each baseline/indicator needs 3 plots\n",
    "    # so total = baseline (3) + (number of indicators * 3)\n",
    "    num_subplots = 3 + (num_indicators * 3)\n",
    "    fig, axes = plt.subplots(num_subplots, 1, sharex='all', sharey='none', figsize=(12, 20))\n",
    "\n",
    "    # Create an Excel writer for exporting data\n",
    "    excel_filename = os.path.join(scenario_output_path, f\"{scenario.name}_dynamic_stocks.xlsx\")\n",
    "    with pd.ExcelWriter(excel_filename) as writer:\n",
    "\n",
    "        all_stock_total_dfs = []\n",
    "        all_stock_change_dfs=[]\n",
    "        all_stock_outflow_dfs=[]\n",
    "        for stock_id, baseline_dsm in stock_id_to_baseline_dsm.items():\n",
    "            plot_index = 0\n",
    "\n",
    "            # Truncate the stock ID to 20 characters (or any suitable length) to fit within the 31 character limit\n",
    "            stock_id_for_filename = stock_id[:20]  # Truncate to the first 20 characters\n",
    "            stock_id_for_filename = stock_id_for_filename.replace(\":\", \"_\")  # Replace \":\" with \"_\"\n",
    "\n",
    "            # ******************\n",
    "            # * Baseline stock *\n",
    "            # ******************\n",
    "            baseline_stock_by_cohort = baseline_dsm.compute_s_c_inflow_driven()\n",
    "            baseline_outflow_by_cohort = baseline_dsm.compute_o_c_from_s_c()\n",
    "            baseline_stock_total = baseline_dsm.compute_stock_total()\n",
    "            baseline_stock_change = baseline_dsm.compute_stock_change()\n",
    "            baseline_stock_outflow = baseline_dsm.compute_outflow_total()\n",
    "\n",
    "            # Export stock by cohort\n",
    "            sheet_name = shorten_sheet_name(f'{stock_id_for_filename}_s_by_c_{baseline_value_name}')\n",
    "            df_baseline_stock_by_cohort = pd.DataFrame(baseline_stock_by_cohort, columns=years, index=years)\n",
    "            df_baseline_stock_by_cohort.to_excel(writer, sheet_name=sheet_name)\n",
    "\n",
    "            # Export outflow by cohort\n",
    "            sheet_name = shorten_sheet_name(f'{stock_id_for_filename}_o_by_c_{baseline_value_name}')\n",
    "            df_baseline_outflow_by_cohort = pd.DataFrame(baseline_outflow_by_cohort, columns=years, index=years)\n",
    "            df_baseline_outflow_by_cohort.to_excel(writer, sheet_name=sheet_name)\n",
    "\n",
    "            # Export stock total\n",
    "            df_baseline_stock_total = pd.DataFrame(baseline_stock_total, index=years)\n",
    "            df_baseline_stock_total.reset_index(inplace=True)\n",
    "            df_baseline_stock_total.columns = [\"Year\", \"Stock total\"]\n",
    "            df_baseline_stock_total[\"Scenario\"] = scenario.name\n",
    "            df_baseline_stock_total[\"Stock ID\"] = stock_id\n",
    "            df_baseline_stock_total[\"Indicator\"] =baseline_unit_name\n",
    "            all_stock_total_dfs.append(df_baseline_stock_total)\n",
    "\n",
    "            # Export stock change\n",
    "            df_baseline_stock_change = pd.DataFrame(baseline_stock_change, index=years)\n",
    "            df_baseline_stock_change.reset_index(inplace=True)\n",
    "            df_baseline_stock_change.columns = [\"Year\", \"Stock change\"]\n",
    "            df_baseline_stock_change[\"Scenario\"] = scenario.name\n",
    "            df_baseline_stock_change[\"Stock ID\"] = stock_id\n",
    "            df_baseline_stock_change[\"Indicator\"] =baseline_unit_name\n",
    "            all_stock_change_dfs.append(df_baseline_stock_change)\n",
    "\n",
    "            # Export stock outflow total\n",
    "            df_baseline_stock_outflow = pd.DataFrame(baseline_stock_outflow, index=years)\n",
    "            df_baseline_stock_outflow.reset_index(inplace=True)\n",
    "            df_baseline_stock_outflow.columns = [\"Year\", \"Stock outflow total\"]\n",
    "            df_baseline_stock_outflow[\"Scenario\"] = scenario.name\n",
    "            df_baseline_stock_outflow[\"Stock ID\"] = stock_id\n",
    "            df_baseline_stock_outflow[\"Indicator\"] =baseline_unit_name\n",
    "            all_stock_outflow_dfs.append(df_baseline_stock_outflow)\n",
    "\n",
    "\n",
    "            # Plot baseline stock total (in-use stocks)\n",
    "            axes[plot_index + 0].plot(years, baseline_stock_total, marker='o', label=\"{}\".format(stock_id))\n",
    "            axes[plot_index + 0].set_ylabel(\"In-use stock ({})\".format(baseline_unit_name))\n",
    "            axes[plot_index + 0].set_title(\"In-use stock per year by product type\")\n",
    "\n",
    "            # Plot baseline stock change\n",
    "            axes[plot_index + 1].plot(years, baseline_stock_change, marker='o', label=f'{stock_id}')\n",
    "            axes[plot_index + 1].set_ylabel(\"Stock change ({})\".format(baseline_unit_name))\n",
    "            axes[plot_index + 1].set_title(\"Stock change per year by product type\")\n",
    "\n",
    "            # Plot baseline outflow by cohort\n",
    "            axes[plot_index + 2].plot(years, baseline_stock_outflow, marker='o', label=f'{stock_id}')\n",
    "            axes[plot_index + 2].set_ylabel(\"Stock outflow ({})\".format(baseline_unit_name))\n",
    "            axes[plot_index + 2].set_title(\"Stock outflow per year by product type\")\n",
    "\n",
    "            plot_index += 3\n",
    "            for indicator_name, indicator_dsm in stock_id_to_indicator_name_to_dsm[stock_id].items():\n",
    "                # **************\n",
    "                # * Indicators *\n",
    "                # **************\n",
    "                indicator_unit = indicators[indicator_name].unit\n",
    "\n",
    "                indicator_stock_by_cohort = indicator_dsm.compute_s_c_inflow_driven()\n",
    "                indicator_outflow_by_cohort = indicator_dsm.compute_o_c_from_s_c()\n",
    "                indicator_stock_total = indicator_dsm.compute_stock_total()\n",
    "                indicator_stock_change = indicator_dsm.compute_stock_change()\n",
    "                indicator_stock_outflow = indicator_dsm.compute_outflow_total()\n",
    "\n",
    "                # Export indicator stock by cohort\n",
    "                sheet_name = shorten_sheet_name(f\"{stock_id_for_filename}_s_by_c_{indicator_name}\")\n",
    "                df_indicator_stock_by_cohort = pd.DataFrame(indicator_stock_by_cohort, columns=years, index=years)\n",
    "                df_indicator_stock_by_cohort.to_excel(writer, sheet_name=sheet_name)\n",
    "\n",
    "                # Export indicator outflow by cohort\n",
    "                sheet_name = shorten_sheet_name(f'{stock_id_for_filename}_o_by_c_{indicator_name}')\n",
    "                df_indicator_oc = pd.DataFrame(indicator_outflow_by_cohort, columns=years, index=years)\n",
    "                df_indicator_oc.to_excel(writer, sheet_name=sheet_name)\n",
    "\n",
    "                # Export indicator stock total\n",
    "                df_indicator_stock_total = pd.DataFrame(indicator_stock_total, index=years)\n",
    "                df_indicator_stock_total.reset_index(inplace=True)\n",
    "                df_indicator_stock_total.columns = [\"Year\", \"Stock total\"]\n",
    "                df_indicator_stock_total[\"Scenario\"] = scenario.name\n",
    "                df_indicator_stock_total[\"Stock ID\"] = stock_id\n",
    "                df_indicator_stock_total[\"Indicator\"] = indicator_name\n",
    "                all_stock_total_dfs.append(df_indicator_stock_total)\n",
    "\n",
    "                #df_indicator_stock_total.to_excel(writer, sheet_name=sheet_name)\n",
    "\n",
    "                # Export indicator stock change\n",
    "                df_indicator_stock_change = pd.DataFrame(indicator_stock_change, index=years)\n",
    "                df_indicator_stock_change.reset_index(inplace=True)\n",
    "                df_indicator_stock_change.columns = [\"Year\", \"Stock change\"]\n",
    "                df_indicator_stock_change[\"Scenario\"] = scenario.name\n",
    "                df_indicator_stock_change[\"Stock ID\"] = stock_id\n",
    "                df_indicator_stock_change[\"Indicator\"] =indicator_name\n",
    "                all_stock_change_dfs.append(df_indicator_stock_change)\n",
    "\n",
    "                # Export indicator stock outflow total\n",
    "                df_indicator_stock_outflow = pd.DataFrame(indicator_stock_outflow, index=years)\n",
    "                df_indicator_stock_outflow.reset_index(inplace=True)\n",
    "                df_indicator_stock_outflow.columns = [\"Year\", \"Stock outflow total\"]\n",
    "                df_indicator_stock_outflow[\"Scenario\"] = scenario.name\n",
    "                df_indicator_stock_outflow[\"Stock ID\"] = stock_id\n",
    "                df_indicator_stock_outflow[\"Indicator\"] =indicator_name\n",
    "                all_stock_outflow_dfs.append(df_indicator_stock_outflow)\n",
    "\n",
    "                # Plot indicator stock total (in-use stocks)\n",
    "                axes[plot_index + 0].plot(years, indicator_stock_total, marker='o', label='{} ({}) {}'.format(\n",
    "                    indicator_name, indicator_unit, stock_id))\n",
    "                axes[plot_index + 0].set_ylabel(\"In-use stock ({})\".format(indicator_unit))\n",
    "                axes[plot_index + 0].set_title(\"{} stock in-use per year by product type\".format(indicator_name))\n",
    "\n",
    "                # Plot indicator stock change\n",
    "                axes[plot_index + 1].plot(years, indicator_stock_change, marker='o', label=\"{} ({}) {}\".format(\n",
    "                    indicator_name, indicator_unit, stock_id))\n",
    "                axes[plot_index + 1].set_ylabel(\"Stock change ({})\".format(indicator_unit))\n",
    "                axes[plot_index + 1].set_title(\"{} stock change per year\".format(indicator_name))\n",
    "\n",
    "                # Plot indicator outflow by cohort\n",
    "                axes[plot_index + 2].plot(years, indicator_stock_outflow, marker='o', label=\"{} ({}) {}\".format(\n",
    "                    indicator_name, indicator_unit, stock_id\n",
    "                ))\n",
    "                axes[plot_index + 2].set_ylabel(\"Stock outflow ({})\".format(indicator_unit))\n",
    "                axes[plot_index + 2].set_title(\"{} outflow per year by product type\".format(indicator_name))\n",
    "\n",
    "                plot_index += 3\n",
    "\n",
    "        if all_stock_total_dfs:\n",
    "            combined_stock_total_df = pd.concat(all_stock_total_dfs, ignore_index=True)\n",
    "            combined_sheet_name = \"Total_stock\"\n",
    "            combined_stock_total_df.to_excel(writer, sheet_name=combined_sheet_name, index=False)\n",
    "\n",
    "        if all_stock_change_dfs:\n",
    "            combined_stock_change_df = pd.concat(all_stock_change_dfs, ignore_index=True)\n",
    "            combined_sheet_name = \"Total_stock_change\"\n",
    "            combined_stock_change_df.to_excel(writer, sheet_name=combined_sheet_name, index=False)\n",
    "\n",
    "        if all_stock_outflow_dfs:\n",
    "            all_stock_outflow_dfs = pd.concat(all_stock_outflow_dfs, ignore_index=True)\n",
    "            combined_sheet_name = \"Total_stock_outflow\"\n",
    "            all_stock_outflow_dfs.to_excel(writer, sheet_name=combined_sheet_name, index=False)\n",
    "\n",
    "        # Set common properties to axes\n",
    "        range_x_ticks = range(min(years), max(years) + 1)\n",
    "        for axis in axes:\n",
    "            axis.set_xlabel(\"Year\")\n",
    "            axis.title.set_size(12)\n",
    "            axis.legend()\n",
    "\n",
    "        # Adjust layout to prevent overlap\n",
    "        plt.tight_layout()\n",
    "        tick_gap = 1 if len(years) < 15 else 10\n",
    "        plt.xticks(years[::tick_gap])\n",
    "\n",
    "        # Save the figure as an SVG file\n",
    "        filename = os.path.join(scenario_output_path, \"{}_stock_plots_by_product.svg\".format(scenario.name))\n",
    "        plt.savefig(filename, format='svg')\n",
    "\n",
    "        if model_params[ParameterName.ShowPlots]:\n",
    "            plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# *****************************************************\n",
    "# * Step 6: Convert the carbon stocks to CO2 removals *\n",
    "# *****************************************************\n",
    "print(\"Calculating annual CO2 stock emissions / removals results...\")\n",
    "\n",
    "# Storage for comparison\n",
    "all_scenario_results = {}\n",
    "all_emitter_years = {}\n",
    "\n",
    "show_steady_state_overlay = False  # Toggle to enable/disable overlay\n",
    "steady_state_threshold_ratio = 0.05  # Relative threshold for stability\n",
    "min_steady_state_years = 5  # Minimum consecutive years for valid steady state\n",
    "\n",
    "for scenario in scenarios:\n",
    "    scenario_output_path = scenario_name_to_output_path[scenario.name]\n",
    "    flow_solver = scenario.flow_solver\n",
    "    years = scenario.scenario_data.years\n",
    "    year_start = scenario.scenario_data.start_year\n",
    "\n",
    "    stock_id_to_indicator_name_to_dsm = flow_solver.get_indicator_dynamic_stocks()\n",
    "    if not len(stock_id_to_indicator_name_to_dsm.keys()):\n",
    "        print(\"Scenario '{}': no dynamic stocks in the defined system\".format(scenario.name))\n",
    "        continue\n",
    "\n",
    "    results_co2_removals = pd.DataFrame({'Year': years})\n",
    "    results_net_emitters = pd.DataFrame({'Year': years})\n",
    "    conversion_factor_c_to_co2 = model_params[ParameterName.ConversionFactorCToCO2]\n",
    "\n",
    "    # Define line styles, markers, and colors for differentiation\n",
    "    line_styles = ['-', '--', '-.', ':']\n",
    "    markers = ['o', 's', '^', 'D']\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "\n",
    "    target_indicator_name = \"Carbon\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    scenario_results = {}\n",
    "    steady_state_info = {}\n",
    "    net_emitter_info = {}\n",
    "\n",
    "    for index, (stock_id, indicator_name_to_dsm) in enumerate(stock_id_to_indicator_name_to_dsm.items()):\n",
    "        if target_indicator_name not in indicator_name_to_dsm:\n",
    "            continue\n",
    "\n",
    "        dsm = indicator_name_to_dsm[target_indicator_name]\n",
    "        total_inflows_carbon = dsm.i\n",
    "        total_outflows_carbon = dsm.o\n",
    "        annual_co2_removal = (total_inflows_carbon - total_outflows_carbon) * conversion_factor_c_to_co2\n",
    "        results_co2_removals[stock_id] = annual_co2_removal\n",
    "        scenario_results[stock_id] = annual_co2_removal\n",
    "\n",
    "# Detect steady-state years with rolling window approach\n",
    "        threshold = steady_state_threshold_ratio * max(abs(annual_co2_removal))\n",
    "        rolling_mean = pd.Series(annual_co2_removal).rolling(window=min_steady_state_years, center=True).mean()\n",
    "        is_steady = abs(pd.Series(annual_co2_removal) - rolling_mean) < threshold\n",
    "\n",
    "# Extract consecutive steady years\n",
    "        steady_years = []\n",
    "        current_run = []\n",
    "        for year, steady in zip(years, is_steady):\n",
    "            if steady:\n",
    "                current_run.append(year)\n",
    "            else:\n",
    "                if len(current_run) >= min_steady_state_years:\n",
    "                    steady_years.extend(current_run)\n",
    "                current_run = []\n",
    "        if len(current_run) >= min_steady_state_years:\n",
    "            steady_years.extend(current_run)\n",
    "\n",
    "        steady_state_info[stock_id] = sorted(set(steady_years))\n",
    "\n",
    "        # Detect net emitter years (negative removals)\n",
    "        emitter_years = [year for year, value in zip(years, annual_co2_removal) if value < 0]\n",
    "        results_net_emitters[stock_id] = [\"Emitter\" if value < 0 else \"\" for value in annual_co2_removal]\n",
    "        net_emitter_info[stock_id] = emitter_years\n",
    "\n",
    "        # Plot CO2 removals with steady state overlay\n",
    "        line_style = line_styles[index % len(line_styles)]\n",
    "        marker = markers[index % len(markers)]\n",
    "        color = colors[index % len(colors)]\n",
    "        plt.plot(years, annual_co2_removal, marker=marker, linestyle=line_style, color=color,\n",
    "                 label=f'{stock_id}')\n",
    "        if show_steady_state_overlay and steady_years:\n",
    "            plt.axvspan(steady_years[0], steady_years[-1], color=color, alpha=0.1)\n",
    "\n",
    "\n",
    "    all_scenario_results[scenario.name] = scenario_results\n",
    "    all_emitter_years[scenario.name] = net_emitter_info\n",
    "\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('CO2 Emissions / Removals (Mt CO2)')\n",
    "    plt.title('Annual CO2 Emissions / Removals by Product')\n",
    "    plt.grid(True)\n",
    "    tick_gap = 1 if len(years) < 15 else 10\n",
    "    plt.xticks(years[::tick_gap])\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Export CO2 removal data to CSV\n",
    "    print(\"Exporting annual CO2 emissions / removal (Mt) by stock results...\")\n",
    "    filename = os.path.join(scenario_output_path, f\"{scenario.name}_annual_co2_removal_by_stock.csv\")\n",
    "    results_co2_removals.to_csv(path_or_buf=filename, index=False, mode=\"w\")\n",
    "\n",
    "    # Export net emitter flag table\n",
    "    print(\"Exporting annual CO2 net emitter years (where removals < 0)...\")\n",
    "    filename = os.path.join(scenario_output_path, f\"{scenario.name}_annual_net_emitter_flags.csv\")\n",
    "    results_net_emitters.to_csv(path_or_buf=filename, index=False, mode=\"w\")\n",
    "\n",
    "    # Export CO2 removal plot as SVG\n",
    "    filename = os.path.join(scenario_output_path, f\"{scenario.name}_annual_co2_removal_by_product.svg\")\n",
    "    plt.savefig(filename, format='svg')\n",
    "\n",
    "    if model_params[ParameterName.ShowPlots]:\n",
    "        plt.show()\n",
    "\n",
    "    # Print and export steady-state info\n",
    "    print(f\"\\nSteady-state periods for scenario '{scenario.name}':\")\n",
    "    for stock_id, years_list in steady_state_info.items():\n",
    "        if years_list:\n",
    "            print(f\"  {stock_id}: {years_list[0]} to {years_list[-1]} ({len(years_list)} years)\")\n",
    "        else:\n",
    "            print(f\"  {stock_id}: No steady-state period detected.\")\n",
    "\n",
    "    steady_state_df = pd.DataFrame([\n",
    "        {'Stock': stock_id, 'StartYear': years_list[0] if years_list else None,\n",
    "         'EndYear': years_list[-1] if years_list else None, 'DurationYears': len(years_list)}\n",
    "        for stock_id, years_list in steady_state_info.items()\n",
    "    ])\n",
    "    filename = os.path.join(scenario_output_path, f\"{scenario.name}_steady_state_periods.csv\")\n",
    "    steady_state_df.to_csv(filename, index=False)\n",
    "\n",
    "# Statistical comparison against baseline\n",
    "print(\"\\nPerforming statistical comparison against baseline...\")\n",
    "import scipy.stats as stats\n",
    "\n",
    "baseline_name = scenarios[0].name\n",
    "baseline_results = all_scenario_results[baseline_name]\n",
    "\n",
    "for scenario in scenarios[1:]:\n",
    "    scenario_name = scenario.name\n",
    "    scenario_results = all_scenario_results[scenario_name]\n",
    "    print(f\"\\nComparison: {scenario_name} vs {baseline_name}\")\n",
    "\n",
    "    for stock_id in baseline_results:\n",
    "        if stock_id not in scenario_results:\n",
    "            continue\n",
    "\n",
    "        baseline_values = baseline_results[stock_id]\n",
    "        scenario_values = scenario_results[stock_id]\n",
    "\n",
    "        if not np.allclose(baseline_values, scenario_values, atol=1e-3):\n",
    "            t_stat, p_value = stats.ttest_rel(baseline_values, scenario_values)\n",
    "            print(f\"  Stock: {stock_id}\")\n",
    "            print(f\"    - Mean (baseline): {np.mean(baseline_values):.2f} Mt\")\n",
    "            print(f\"    - Mean ({scenario_name}): {np.mean(scenario_values):.2f} Mt\")\n",
    "            print(f\"    - Std Dev (baseline): {np.std(baseline_values):.2f} Mt\")\n",
    "            print(f\"    - Std Dev ({scenario_name}): {np.std(scenario_values):.2f} Mt\")\n",
    "            print(f\"    - Net Balance Change: {sum(scenario_values) - sum(baseline_values):.2f} Mt\")\n",
    "            print(f\"    - p-value: {p_value:.4f}\")\n",
    "\n",
    "            # Save plot for changed stocks\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            plt.plot(years, baseline_values, label=f\"{baseline_name}\", linestyle=\"--\")\n",
    "            plt.plot(years, scenario_values, label=f\"{scenario_name}\", linestyle=\"-\")\n",
    "            plt.title(f\"CO2 Comparison for {stock_id}\")\n",
    "            plt.xlabel(\"Year\")\n",
    "            plt.ylabel(\"CO2 Emissions / Removals (Mt CO2)\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            comp_filename = os.path.join(scenario_name_to_output_path[scenario_name], f\"comparison_{stock_id}.svg\")\n",
    "            plt.savefig(comp_filename, format=\"svg\")\n",
    "\n",
    "# Export automatic markdown summary report\n",
    "print(\"\\nGenerating automatic summary report...\")\n",
    "report_lines = []\n",
    "report_lines.append(\"# CO₂ Removal Analysis Summary\\n\")\n",
    "for scenario_name, scenario_data in all_scenario_results.items():\n",
    "    report_lines.append(f\"## Scenario: {scenario_name}\\n\")\n",
    "    for stock_id, removals in scenario_data.items():\n",
    "        net_balance = np.sum(removals)\n",
    "        mean_val = np.mean(removals)\n",
    "        std_val = np.std(removals)\n",
    "        emit_years = all_emitter_years[scenario_name].get(stock_id, [])\n",
    "        report_lines.append(f\"- **{stock_id}**: Net balance = {net_balance:.2f} Mt, Mean = {mean_val:.2f} Mt, Std = {std_val:.2f} Mt\\n\")\n",
    "        if emit_years:\n",
    "            report_lines.append(f\"    - Emits CO₂ in years: {', '.join(map(str, emit_years))}\\n\")\n",
    "report_text = \"\\n\".join(report_lines)\n",
    "summary_filename = os.path.join(scenario_name_to_output_path[baseline_name], \"summary_report.md\")\n",
    "with open(summary_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report_text)\n",
    "print(f\"Summary report saved to: {summary_filename}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ************************************************************\n",
    "# * Step 7: Visualize inflows per year to selected processes *\n",
    "# ************************************************************\n",
    "\n",
    "# This is only done only when there is multiple years\n",
    "# Visualize inflows per year to processes\n",
    "visualize_inflows_to_process_ids = model_params[ParameterName.VisualizeInflowsToProcesses]\n",
    "for scenario in scenarios:\n",
    "    scenario_output_path = scenario_name_to_output_path[scenario.name]\n",
    "    flow_solver = scenario.flow_solver\n",
    "    years = scenario.scenario_data.years\n",
    "\n",
    "    # Dictionary: Process ID to process\n",
    "    unique_processes = flow_solver.get_unique_processes()\n",
    "    for process_id in visualize_inflows_to_process_ids:\n",
    "        process = flow_solver.get_process(process_id, min(years))\n",
    "        flow_id_to_source_process_id = {}\n",
    "        source_process_names = []\n",
    "\n",
    "        # Find all source processes of all incoming flows to this process in all years\n",
    "        # This is needed to create stable set of process names so that the relative\n",
    "        # position of the processes stay the same in stacked chart between the years\n",
    "        source_process_ids = set()\n",
    "        for year in years:\n",
    "            inflows = flow_solver.get_process_flows(process_id, year)[\"Inflows\"]\n",
    "            unique_flow_ids = set()\n",
    "            for flow in inflows:\n",
    "                unique_flow_ids.add(flow.id)\n",
    "                flow_id_to_source_process_id[flow.id] = flow.source_process_id\n",
    "\n",
    "            # Find source process ID of each incoming flow and add\n",
    "            # to list of unique source process IDs if not already there\n",
    "            unique_flow_ids = list(unique_flow_ids)\n",
    "            for flow_id in unique_flow_ids:\n",
    "                source_process_ids.add(flow_id_to_source_process_id[flow_id])\n",
    "\n",
    "        # Now source_process_ids-list contains list of all the possible process IDs\n",
    "        # that have flows incoming to process_id. This list is needed to keep the\n",
    "        # incoming process IDs the same every year because aiphoria allows the connections\n",
    "        # between the flows to change between the years.\n",
    "        source_process_ids = list(source_process_ids)\n",
    "\n",
    "        # Create 2D array with shape of (number of source process IDs, number of years)\n",
    "        # and fill with the value of the inflow from source process for each year\n",
    "        df_inflows_to_process = pd.DataFrame(columns=['Year', 'Source Process ID', 'Value ({})'.format(\n",
    "            model_params[ParameterName.BaselineUnitName])])\n",
    "        source_process_by_flow_values = np.ndarray(shape=(len(source_process_ids), len(years)))\n",
    "        for year_index, year in enumerate(years):\n",
    "            inflows = flow_solver.get_process_flows(process_id, year)[\"Inflows\"]\n",
    "            for flow in inflows:\n",
    "                source_process_id_index = source_process_ids.index(flow.source_process_id)\n",
    "                source_process_by_flow_values[source_process_id_index, year_index] = flow.evaluated_value\n",
    "                df_inflows_to_process.loc[len(df_inflows_to_process)] = [year, flow.source_process_id,\n",
    "                                                                         flow.evaluated_value]\n",
    "        df_inflows_to_process = df_inflows_to_process.round(5)\n",
    "\n",
    "        # Export inflows to process to CSV file\n",
    "        # NOTE: Replace character ':' in Process ID to underscore because Windows system are not able to handle that character in filename\n",
    "        process_id_for_filename = process_id.replace(\":\", \"_\")\n",
    "        filename = os.path.join(scenario_output_path,\n",
    "                                \"{}_inflows_to_{}.csv\".format(scenario.name, process_id_for_filename))\n",
    "        df_inflows_to_process.to_csv(path_or_buf=filename, index=False, mode=\"w\")\n",
    "\n",
    "        # Initialize the figure and axes for the stacked area chart\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        ax.stackplot(years, source_process_by_flow_values, labels=list(source_process_ids))\n",
    "        ax.set_ylabel(\"Mm3 SWE\")\n",
    "        ax.set_title(\"Inputs to {}\".format(process.name))\n",
    "        ax.legend(loc='upper left')\n",
    "        tick_gap = 1 if len(years) < 15 else 10\n",
    "        plt.xticks(years[::tick_gap])\n",
    "\n",
    "        # Save the figure as an SVG file\n",
    "        filename = os.path.join(scenario_output_path,\n",
    "                                \"{}_inflows_to_{}.svg\".format(scenario.name, process_id_for_filename))\n",
    "        plt.savefig(filename, format='svg')\n",
    "\n",
    "        if model_params[ParameterName.ShowPlots]:\n",
    "            plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# *****************************************************\n",
    "# * Step 8: Visualize the flow graph as Sankey graph *\n",
    "# *****************************************************\n",
    "\n",
    "# Create color name to color value mapping\n",
    "transformation_stage_name_to_color = {color.name: color.value for color in dataprovider.get_color_definitions()}\n",
    "\n",
    "# Virtual process graph label overrides\n",
    "# TODO: Move also this to settings file?\n",
    "virtual_process_graph_labels = dict()\n",
    "virtual_process_graph_labels[\"VP_P2:EU\"] = \"Unreported flow from P2\"\n",
    "virtual_process_graph_labels[\"VP_P3:EU\"] = \"Unreported flow from P3\"\n",
    "\n",
    "# Virtual Process and virtual Flow colors\n",
    "visualizer_params = {\n",
    "    # User can hide processes in Sankey graph that have total inflows less than this value\n",
    "    # This value cannot be changed now in the Sankey graph\n",
    "    # TODO: Move this to settings file?\n",
    "    \"small_node_threshold\": 5,\n",
    "\n",
    "    # Dictionary to define labels for virtual flows\n",
    "    # If dictionary contains label for the virtual process then that is used,\n",
    "    # otherwise the virtual process ID is used\n",
    "    \"virtual_process_graph_labels\": virtual_process_graph_labels,\n",
    "\n",
    "    # Dictionary to define color of process by the process transformation stage name\n",
    "    # All must be provided as a RGB hex string, prefixed by character '#'\n",
    "    # Usage example: { \"Source\": \"#707070\" }\n",
    "    \"process_transformation_stage_colors\": transformation_stage_name_to_color,\n",
    "\n",
    "    # How transparent flows are (0.0 = invisible, 1.0 = fully opaque)\n",
    "    \"flow_alpha\": 0.75,\n",
    "\n",
    "    # Color for virtual process\n",
    "    \"virtual_process_color\": \"rgba(0.3, 0.3, 0.3, 0.6)\",\n",
    "    #\"virtual_process_color\": \"#707070\",\n",
    "\n",
    "    # Color for virtual flows\n",
    "    \"virtual_flow_color\": \"#808080\",\n",
    "}\n",
    "\n",
    "# NOTE: Now each scenario is in it's own graph\n",
    "if model_params[ParameterName.CreateSankeyCharts]:\n",
    "    visualizer = DataVisualizer()\n",
    "    visualizer.build_and_show(scenarios, visualizer_params, model_params)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
